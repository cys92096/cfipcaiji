name: Scrape Cloudflare Top IPs

on:
  schedule:
    - cron: '0 */2 * * *'
  workflow_dispatch: # 允许手动触发

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.x'

    - name: Install dependencies
      run: |
        pip install beautifulsoup4 selenium webdriver_manager # 只保留需要的库
        # pandas不再需要，因为我们不再处理DataFrame

    - name: Setup Chrome
      uses: browser-actions/setup-chrome@v1
      with:
        chrome-version: 'stable'

    - name: Run IP extraction script
      run: python extract_ips_selenium.py # 确保文件名正确

    - name: Commit and push changes
      run: |
        git config user.name "GitHub Actions Bot"
        git config user.email "actions@github.com"
        
        # 确保data目录存在，即使脚本没有创建文件，或为了git add data/cloudflare_top10_ips.txt能找到目录
        mkdir -p data 
        
        # 检查文件是否存在且有内容，避免空文件提交
        if [ -s data/cloudflare_top10_ips.txt ]; then
          git add data/cloudflare_top10_ips.txt
          git commit -m "Automated Cloudflare Top 10 IPs update ($(date +%Y-%m-%d %H:%M))" || echo "No changes to commit"
          git push
        else
          echo "No valid IP data file generated or file is empty, skipping commit."
        fi
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
